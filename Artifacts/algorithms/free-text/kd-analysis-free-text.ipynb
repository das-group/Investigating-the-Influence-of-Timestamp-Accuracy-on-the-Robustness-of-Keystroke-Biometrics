{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Self\n",
    "from collections import defaultdict\n",
    "\n",
    "minimum_profile_length_r: int = 5\n",
    "minimum_profile_length_a: int = 5\n",
    "data_folder = \"__DATA_28_test_test\"\n",
    "filter = [13, 18, 26]\n",
    "\n",
    "\n",
    "# control log level\n",
    "trace: bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create and read user profiles\n",
    "def keystrokes_to_digraphs(keystroke_array):\n",
    "    digraphs = []\n",
    "    i = 0\n",
    "    while i < len(keystroke_array) - 1:\n",
    "        digraphs.append(\n",
    "            (\n",
    "                str(keystroke_array[i][0]) + \"-\" + str(keystroke_array[i + 1][0]),\n",
    "                np.round((keystroke_array[i + 1][1] - keystroke_array[i][1]), 5),\n",
    "            )\n",
    "        )\n",
    "        i += 1\n",
    "    return digraphs\n",
    "\n",
    "\n",
    "def keystrokes_to_trigraphs(keystroke_array):\n",
    "    trigraphs = []\n",
    "    i = 0\n",
    "    while i < len(keystroke_array) - 2:\n",
    "        trigraphs.append(\n",
    "            (\n",
    "                str(keystroke_array[i][0])\n",
    "                + \"-\"\n",
    "                + str(keystroke_array[i + 1][0])\n",
    "                + \"-\"\n",
    "                + str(keystroke_array[i + 2][0]),\n",
    "                np.round((keystroke_array[i + 2][1] - keystroke_array[i][1]), 5),\n",
    "            )\n",
    "        )\n",
    "        i += 1\n",
    "    return trigraphs\n",
    "\n",
    "\n",
    "def keystrokes_to_fourgraphs(keystroke_array):\n",
    "    fourgraphs = []\n",
    "    i = 0\n",
    "    while i < len(keystroke_array) - 3:\n",
    "        fourgraphs.append(\n",
    "            (\n",
    "                str(keystroke_array[i][0])\n",
    "                + \"-\"\n",
    "                + str(keystroke_array[i + 1][0])\n",
    "                + \"-\"\n",
    "                + str(keystroke_array[i + 2][0])\n",
    "                + \"-\"\n",
    "                + str(keystroke_array[i + 3][0]),\n",
    "                np.round((keystroke_array[i + 3][1] - keystroke_array[i][1]), 5),\n",
    "            )\n",
    "        )\n",
    "        i += 1\n",
    "    return fourgraphs\n",
    "\n",
    "\n",
    "def calculate_mean_for_duplicates(ngraphs):\n",
    "    cleaned_ngraphs = []\n",
    "    processed_keys = []\n",
    "    for key, time in ngraphs:\n",
    "        if key not in processed_keys:\n",
    "            duplicates = [e for e in ngraphs if e[0] == key]\n",
    "            if len(duplicates) > 1:\n",
    "                processed_keys.append(key)\n",
    "                cleaned_ngraphs.append(\n",
    "                    (key, np.round(np.mean([d[1] for d in duplicates]), 5))\n",
    "                )\n",
    "            else:\n",
    "                processed_keys.append(key)\n",
    "                cleaned_ngraphs.append((key, time))\n",
    "    return cleaned_ngraphs\n",
    "\n",
    "\n",
    "def create_user_profile(keystroke_sequence):\n",
    "    digraphs = calculate_mean_for_duplicates(keystrokes_to_digraphs(keystroke_sequence))\n",
    "    trigraphs = calculate_mean_for_duplicates(\n",
    "        keystrokes_to_trigraphs(keystroke_sequence)\n",
    "    )\n",
    "    fourgraphs = calculate_mean_for_duplicates(\n",
    "        keystrokes_to_fourgraphs(keystroke_sequence)\n",
    "    )\n",
    "    return digraphs, trigraphs, fourgraphs\n",
    "\n",
    "\n",
    "def read_file(complete: pd.DataFrame, user: int, set: int) -> list[(str, int)]:\n",
    "    key_codes = complete.loc[(complete[\"user\"] == user) & (complete[\"set\"] == set)][\n",
    "        \"key\"\n",
    "    ].to_list()\n",
    "    timestamps = complete.loc[(complete[\"user\"] == user) & (complete[\"set\"] == set)][\n",
    "        \"timestamp\"\n",
    "    ].to_list()\n",
    "\n",
    "    keystrokes = [(str(k), t) for (k, t) in zip(key_codes, timestamps)]\n",
    "\n",
    "    return keystrokes\n",
    "\n",
    "\n",
    "def read_user_data(complete):\n",
    "    users = []\n",
    "\n",
    "    for user in range(1, 32):\n",
    "        tmp_keystrokes = []\n",
    "        for set in range(1, 16):\n",
    "            f = read_file(complete, user, set)\n",
    "            tmp_keystrokes.append(f)\n",
    "        users.append(tmp_keystrokes)\n",
    "    return users\n",
    "\n",
    "\n",
    "def get_user_profiles(user_data):\n",
    "    user_profiles = []\n",
    "    count = 0\n",
    "    for u_data in user_data:\n",
    "        digraphs = []\n",
    "        trigraphs = []\n",
    "        fourgraphs = []\n",
    "        for sample in u_data:\n",
    "            tmp_digraphs, tmp_trigraphs, tmp_fourgraphs = create_user_profile(sample)\n",
    "            digraphs.append(dict(tmp_digraphs))\n",
    "            trigraphs.append(dict(tmp_trigraphs))\n",
    "            fourgraphs.append(dict(tmp_fourgraphs))\n",
    "\n",
    "        user_profiles.append(\n",
    "            {\"digraphs\": digraphs, \"trigraphs\": trigraphs, \"fourgraphs\": fourgraphs}\n",
    "        )\n",
    "        count += 1\n",
    "    return user_profiles\n",
    "\n",
    "\n",
    "def create_user_profiles(path_to_userdata, filename):\n",
    "    user_data2 = read_user_data(pd.read_csv(path_to_userdata))\n",
    "    user_profiles = get_user_profiles(user_data2)\n",
    "    with open(filename, \"wb\") as fp:\n",
    "        pickle.dump(user_profiles, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abstractions\n",
    "class Sample:\n",
    "    def __init__(\n",
    "        self,\n",
    "        digraphs: dict[str, float],\n",
    "        trigraphs: dict[str, float],\n",
    "        fourgraphs: dict[str, float],\n",
    "    ):\n",
    "        self.digraphs = digraphs\n",
    "        self.trigraphs = trigraphs\n",
    "        self.fourgraphs = fourgraphs\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"digraphs: {self.digraphs} trigraphs: {self.trigraphs} fourgraphs: {self.fourgraphs}\"\n",
    "\n",
    "    def get_intersection(self, other: Self) -> Self:\n",
    "        intersection_digraphs = self.digraphs.keys() & other.digraphs.keys()\n",
    "        intersection_trigraphs = self.trigraphs.keys() & other.trigraphs.keys()\n",
    "        intersection_fourgraphs = self.fourgraphs.keys() & other.fourgraphs.keys()\n",
    "\n",
    "        s_digraphs = {\n",
    "            k: v for k, v in self.digraphs.items() if k in intersection_digraphs\n",
    "        }\n",
    "        s_trigraphs = {\n",
    "            k: v for k, v in self.trigraphs.items() if k in intersection_trigraphs\n",
    "        }\n",
    "        s_fourgraphs = {\n",
    "            k: v for k, v in self.fourgraphs.items() if k in intersection_fourgraphs\n",
    "        }\n",
    "\n",
    "        return Sample(s_digraphs, s_trigraphs, s_fourgraphs)\n",
    "\n",
    "    def get_digraphs(self) -> dict[str, float]:\n",
    "        return self.digraphs\n",
    "\n",
    "    def get_trigraphs(self) -> dict[str, float]:\n",
    "        return self.trigraphs\n",
    "\n",
    "    def get_fourgraphs(self) -> dict[str, float]:\n",
    "        return self.fourgraphs\n",
    "\n",
    "\n",
    "class UserProfile:\n",
    "    def __init__(self, profile: dict[str, list[dict]]):\n",
    "\n",
    "        assert (\n",
    "            len(profile[\"digraphs\"])\n",
    "            == len(profile[\"trigraphs\"])\n",
    "            == len(profile[\"fourgraphs\"])\n",
    "        )\n",
    "\n",
    "        self.digraphs = profile[\"digraphs\"]\n",
    "        self.trigraphs = profile[\"trigraphs\"]\n",
    "        self.fourgraphs = profile[\"fourgraphs\"]\n",
    "        self.m_cache = None\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"digraphs: {self.digraphs} trigraphs: {self.trigraphs} fourgraphs: {self.fourgraphs}\"\n",
    "\n",
    "    def get_sample_count(self) -> int:\n",
    "        return len(self.digraphs)\n",
    "\n",
    "    def get_sample(self, index: int) -> Sample:\n",
    "        return Sample(\n",
    "            self.digraphs[index], self.trigraphs[index], self.fourgraphs[index]\n",
    "        )\n",
    "\n",
    "    def get_samples(self) -> list[Sample]:\n",
    "        out = [self.get_sample(i) for i in range(self.get_sample_count())]\n",
    "        return out\n",
    "\n",
    "    def m_without_x(self,x) -> dict[str, float]:\n",
    "        if x > 14:\n",
    "            print(\"sample\" + str(x))\n",
    "\n",
    "        samples: list[Sample] = self.get_samples()\n",
    "\n",
    "        distances: dict[str, list[float]] = defaultdict(list)\n",
    "\n",
    "        # calculate distances from each set in profile\n",
    "        count_combinations = 0\n",
    "        for i, sample_A in enumerate(samples):\n",
    "            if i == x:\n",
    "                continue\n",
    "            count_combinations += 1\n",
    "            for j, sample_B in enumerate(samples):\n",
    "                if j == x:\n",
    "                    continue\n",
    "                # distance from same sample does not have to be calculated\n",
    "                if j == i:\n",
    "                    assert sample_A == sample_B\n",
    "                    continue\n",
    "\n",
    "                # calculate distance between two samples\n",
    "                distance_combinations: dict[str, float] = d(sample_A, sample_B)\n",
    "\n",
    "                # append each distance to distances\n",
    "                for key, value in distance_combinations.items():\n",
    "                    distances[key].append(value)\n",
    "\n",
    "\n",
    "        return {k: np.array(v).mean() for k, v in distances.items()}\n",
    "\n",
    "    def m(self) -> dict[str, float]:\n",
    "        # check if m was already calculated for this profile\n",
    "        if self.m_cache is not None:\n",
    "            return self.m_cache\n",
    "\n",
    "        samples: list[Sample] = self.get_samples()\n",
    "\n",
    "        distances: dict[str, list[float]] = defaultdict(list)\n",
    "\n",
    "        # calculate distances from each set in profile\n",
    "        for i, sample_A in enumerate(samples):\n",
    "            for j, sample_B in enumerate(samples):\n",
    "                # distance from same sample does not have to be calculated\n",
    "                if j == i:\n",
    "                    assert sample_A == sample_B\n",
    "                    continue\n",
    "\n",
    "                # calculate distance between two samples\n",
    "                distance_combinations: dict[str, float] = d(sample_A, sample_B)\n",
    "\n",
    "                # append each distance to distances\n",
    "                for key, value in distance_combinations.items():\n",
    "                    distances[key].append(value)\n",
    "\n",
    "        # calculate mean for each distance and return\n",
    "        self.m_cache = {k: np.array(v).mean() for k, v in distances.items()}\n",
    "        return self.m_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic distances\n",
    "def a_distance(\n",
    "    sample_A_ngraphs: dict[str, float],\n",
    "    sample_B_ngraphs: dict[str, float],\n",
    "    threshold: float = 1.05,\n",
    ") -> float:\n",
    "\n",
    "    assert len(sample_A_ngraphs) == len(sample_B_ngraphs)\n",
    "\n",
    "    # check that a minimal number of digraphs are shared\n",
    "    number_of_shared_ngraphs = len(sample_A_ngraphs)\n",
    "    if number_of_shared_ngraphs < minimum_profile_length_a:\n",
    "        if trace:print(f\"[TRACE]: Insufficient number of n-graphs: {number_of_shared_ngraphs}\")\n",
    "        return 1\n",
    "\n",
    "    similar_ngraphs: int = 0\n",
    "\n",
    "    # for each n-graph\n",
    "    for n_graph in sample_A_ngraphs:\n",
    "\n",
    "        d1: float = sample_A_ngraphs[n_graph]\n",
    "        d2: float = sample_B_ngraphs[n_graph]\n",
    "\n",
    "        # if distance for two inputs is 0,\n",
    "        # set to very small number, to prevent division by 0\n",
    "        # TODO: is this ok?\n",
    "        if d1 == 0:\n",
    "            d1 = 0.0000001\n",
    "\n",
    "        if d2 == 0:\n",
    "            d2 = 0.0000001\n",
    "\n",
    "        # 1 < max(d1, d2)/min(d1, d2) ≤ t\n",
    "        if 1 < max(d1, d2) / min(d1, d2) <= threshold:\n",
    "            similar_ngraphs += 1\n",
    "\n",
    "    distance: float = 1 - (similar_ngraphs / number_of_shared_ngraphs)\n",
    "\n",
    "    return np.round(distance, 6)\n",
    "\n",
    "\n",
    "def r_distance(\n",
    "    sample_A_ngraphs: dict[str, float], sample_B_ngraphs: dict[str, float]\n",
    ") -> float:\n",
    "    assert len(sample_A_ngraphs) == len(sample_B_ngraphs)\n",
    "\n",
    "    # check that a minimal number of digraphs are shared\n",
    "    number_of_shared_ngraphs = len(sample_A_ngraphs)\n",
    "    if number_of_shared_ngraphs < minimum_profile_length_a:\n",
    "        if trace:print(f\"[TRACE]: Insufficient number of n-graphs: {number_of_shared_ngraphs}\")\n",
    "        return 1\n",
    "\n",
    "    # order reference(user profile) n-graphs based on n-grpah duration\n",
    "    sample_A_ngraphs_sorted = list(dict(sorted(sample_A_ngraphs.items(), key=lambda item: item[1])))\n",
    "\n",
    "    # order sample n-graphs based on n-grpah duration\n",
    "    sample_B_ngraphs_sorted = list(dict(sorted(sample_B_ngraphs.items(), key=lambda item: item[1])))\n",
    "\n",
    "    # calculate distances between n-graph positions in reference and evaluation datasets\n",
    "    ordered_distances = [abs(sample_A_ngraphs_sorted.index(ele) - idx)for idx, ele in enumerate(sample_B_ngraphs_sorted)]\n",
    "\n",
    "    # calculate maximum degree of disorder\n",
    "    # (if |V| is even) 0> (|V|^2 / 2)\n",
    "    if number_of_shared_ngraphs % 2 == 0:\n",
    "        maximum_disorder = ((number_of_shared_ngraphs * number_of_shared_ngraphs)) / 2\n",
    "    # (if |V| is odd) => (|V|^2 − 1) / 2\n",
    "    else:\n",
    "        maximum_disorder = (\n",
    "            (number_of_shared_ngraphs * number_of_shared_ngraphs) - 1\n",
    "        ) / 2\n",
    "\n",
    "    # calculate r-distance\n",
    "    distance = np.sum(ordered_distances) / maximum_disorder\n",
    "\n",
    "    return np.round(distance, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generic d(distance) and md(mean distance) functions\n",
    "def d(sample_A: Sample, sample_B: Sample) -> dict[str, float]:\n",
    "\n",
    "    # get shared n-graphs\n",
    "    shared_sample_A = sample_A.get_intersection(sample_B)\n",
    "    shared_sample_B = sample_B.get_intersection(sample_A)\n",
    "\n",
    "    assert (shared_sample_A.get_digraphs().keys() == shared_sample_B.get_digraphs().keys())\n",
    "    assert (shared_sample_A.get_trigraphs().keys() == shared_sample_B.get_trigraphs().keys())\n",
    "    assert (shared_sample_A.get_fourgraphs().keys()== shared_sample_B.get_fourgraphs().keys())\n",
    "\n",
    "    # get basic distances\n",
    "    a2 = a_distance(shared_sample_A.get_digraphs(), shared_sample_B.get_digraphs())\n",
    "    a3 = a_distance(shared_sample_A.get_trigraphs(), shared_sample_B.get_trigraphs())\n",
    "    a4 = a_distance(shared_sample_A.get_fourgraphs(), shared_sample_B.get_fourgraphs())\n",
    "\n",
    "    r2 = r_distance(shared_sample_A.get_digraphs(), shared_sample_B.get_digraphs())\n",
    "    r3 = r_distance(shared_sample_A.get_trigraphs(), shared_sample_B.get_trigraphs())\n",
    "    r4 = r_distance(shared_sample_A.get_fourgraphs(), shared_sample_B.get_fourgraphs())\n",
    "\n",
    "    # will contain all combinations of a- and r-distances\n",
    "    out: dict[str, float] = {}\n",
    "\n",
    "    out[\"a2\"] = a2\n",
    "    out[\"a3\"] = a3\n",
    "    out[\"a4\"] = a4\n",
    "\n",
    "    out[\"r2\"] = r2\n",
    "    out[\"r3\"] = r3\n",
    "    out[\"r4\"] = r4\n",
    "\n",
    "    out[\"a23\"] = a2 + a3\n",
    "    out[\"a34\"] = a3 + a4\n",
    "    out[\"a234\"] = a2 + a3 + a4\n",
    "\n",
    "    out[\"r23\"] = r2 + r3\n",
    "    out[\"r34\"] = r3 + r4\n",
    "    out[\"r234\"] = r2 + r3 + r4\n",
    "\n",
    "    out[\"r2_a2\"] = r2 + a2\n",
    "    out[\"r3_a3\"] = r3 + a3\n",
    "    out[\"r4_a4\"] = r4 + a4\n",
    "\n",
    "    out[\"r23_a23\"] = r2 + r3 + a2 + a3\n",
    "    out[\"r34_a34\"] = r3 + r4 + a3 + a4\n",
    "    out[\"r24_a24\"] = r2 + r4 + a2 + a4\n",
    "\n",
    "    out[\"r234_a234\"] = r2 + r3 + r4 + a2 + a3 + a4\n",
    "\n",
    "    out[\"r2_a3\"] = r2 + a3\n",
    "    out[\"r2_a4\"] = r2 + a4\n",
    "\n",
    "    out[\"r2_a24\"] = r2 + a2 + a4\n",
    "\n",
    "    out[\"r3_a2\"] = r3 + a2\n",
    "    out[\"r4_a2\"] = r4 + a2\n",
    "\n",
    "    out[\"r23_a2\"] = r2 + r3 + a2\n",
    "    out[\"r23_a3\"] = r2 + r3 + a3\n",
    "    out[\"r23_a4\"] = r2 + r3 + a4\n",
    "\n",
    "    out[\"r234_a2\"] = r2 + r3 + r4 + a2\n",
    "    out[\"r234_a3\"] = r2 + r3 + r4 + a3\n",
    "    out[\"r234_a4\"] = r2 + r3 + r4 + a4\n",
    "\n",
    "    out[\"r234_a23\"] = r2 + r3 + r4 + a2 + a3\n",
    "\n",
    "    out[\"r2_a234\"] = r2 + a2 + a3 + a4\n",
    "    out[\"r3_a234\"] = r3 + a2 + a3 + a4\n",
    "    out[\"r4_a234\"] = r4 + a2 + a3 + a4\n",
    "\n",
    "    out[\"r23_a234\"] = r2 + r3 + a2 + a3 + a4\n",
    "    out[\"r34_a234\"] = r3 + r4 + a2 + a3 + a4\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def md(user: UserProfile, sample: Sample, user_sample_skip: None | int = None) -> dict[str, float]:\n",
    "    \"\"\"\n",
    "    Calculates the mean distances between the user profile and the sample.\n",
    "\n",
    "            Parameters:\n",
    "                    user (UserProfile): A user profile to calculate the distance to\n",
    "                    sample (Sample): A sample to calculate the distance from\n",
    "                    user_sample_skip (optional int): An index for a sample to skip\n",
    "\n",
    "            Returns:\n",
    "                    index (dict[str, float]): The mean distance combinations\n",
    "    \"\"\"\n",
    "    assert isinstance(user, UserProfile), f\"Wrong input type: {type(user)}\"\n",
    "    assert isinstance(sample, Sample), f\"Wrong input type: {type(sample)}\"\n",
    "\n",
    "    distances: dict[str, list[float]] = defaultdict(list)\n",
    "\n",
    "    # calculate distance to each set from user profile\n",
    "    for i, user_sample in enumerate(user.get_samples()):\n",
    "        # skip this sample\n",
    "        if user_sample_skip is not None and user_sample_skip == i:\n",
    "            continue\n",
    "\n",
    "        distance_combinations: dict[str, float] = d(user_sample, sample)\n",
    "\n",
    "        # append each distance to distances\n",
    "        for key, value in distance_combinations.items():\n",
    "            distances[key].append(value)\n",
    "\n",
    "    # calculate mean for each distance and return\n",
    "    return {k: np.array(v).mean() for k, v in distances.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user classification\n",
    "def user_classification(distances: dict[str, list[float]], distance_measure: str) -> int:\n",
    "\n",
    "    # will contains the r234_a23 distance for each user\n",
    "    user_distances = distances[distance_measure]\n",
    "\n",
    "    # returns the index(user) with the minimal distance\n",
    "    return np.argmin(user_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user authentification\n",
    "def authentification(mean_distances: dict[str, list[float]], measure: str, attacked_user: UserProfile, attacked_index: int) -> bool:\n",
    "    # get the mean distance of the UserProfile\n",
    "    m_A = attacked_user.m()[measure]\n",
    "\n",
    "    # get the mean distance from UserProfile to sample\n",
    "    md_A_X = mean_distances[measure][attacked_index]\n",
    "\n",
    "    # check, that distance from UserProfile to sample is small enought\n",
    "    for md_B_X in mean_distances[measure]:\n",
    "        # md(A, X) < m(A) + 0.5[md(B,X) − m(A)]\n",
    "        if not md_A_X < m_A + (0.5 * (md_B_X - m_A)):\n",
    "            # some other UserProfile has small enought distance to sample, authentification fail\n",
    "            return False\n",
    "        \n",
    "    # \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user authentification for attacker sample belonging to attacked user\n",
    "def authentification_legitimate(mean_distances: dict[str, list[float]], measure: str, attacked_user: UserProfile, attacked_index: int, sample_index: int) -> bool:\n",
    "    # get the mean distance of the UserProfile\n",
    "    m_A = attacked_user.m_without_x(sample_index)[measure]\n",
    "\n",
    "    # get the mean distance from UserProfile to sample\n",
    "    md_A_X = mean_distances[measure][attacked_index]\n",
    "\n",
    "    # check, that distance from UserProfile to sample is small enought\n",
    "    for index, md_B_X in  enumerate(mean_distances[measure]):\n",
    "        if index != attacked_index:\n",
    "            # md(A, X) < m(A) + 0.5[md(B,X) − m(A)]\n",
    "            if not md_A_X < m_A + (0.5 * (md_B_X - m_A)):\n",
    "                # some other UserProfile has small enought distance to sample, authentification fail\n",
    "                return False\n",
    "        \n",
    "    # \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean distances(md) calculation\n",
    "def get_mean_distances(attacked_user_profiles: list[UserProfile], attacker_sample: Sample, attacker_sample_idx: int, attacker_index: int) -> dict[str, list[float]]:\n",
    "    \"\"\"\n",
    "    Calculates the mean distances between each user profile and the sample.\n",
    "\n",
    "            Parameters:\n",
    "                    attacked_user_profiles (list[UserProfile]): List of UserProfile to calculte distance from\n",
    "                    attacker_sample (Sample): A sample to calculate the distance to\n",
    "                    attacker_sample_idx (int): Index of sample\n",
    "                    attacker_index (int): Index of attacker Profile the Sample comes from \n",
    "\n",
    "            Returns:\n",
    "                    index (dict[str, list[float]]): Returns the mean distance from each UserProfile to sample for each distance measure\n",
    "    \"\"\"\n",
    "\n",
    "    # calculate distances from sample to user profiles\n",
    "    distances: list[dict[str, float]] = []\n",
    "    for attacked_index, user_profile in enumerate(attacked_user_profiles):\n",
    "        # its the same user,\n",
    "        # pass sample index to skip this sample\n",
    "        if attacked_index == attacker_index:\n",
    "            distance = md(user_profile, attacker_sample, attacker_sample_idx)\n",
    "            distances.append(distance)\n",
    "        # it not the same user, don't skip sample\n",
    "        else:\n",
    "            distance = md(user_profile, attacker_sample, None)\n",
    "            distances.append(distance)\n",
    "\n",
    "\n",
    "    # transform from list of dicts to dict of lists\n",
    "    distances_converted: dict[str, list[float]] = defaultdict(list)\n",
    "    for entry in distances:\n",
    "        for key, value in entry.items():\n",
    "            distances_converted[key].append(value)\n",
    "\n",
    "    return distances_converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute experiment\n",
    "def execute(\n",
    "    user_profiles_training: list[UserProfile],\n",
    "    user_profiles_evaluation: list[UserProfile],\n",
    ") -> dict[str, list[dict]]:\n",
    "    # keys\n",
    "    FRA = \"FalseRejectAttempt\"\n",
    "    FAA = \"FalseAcceptAttempt\"\n",
    "    FRS = \"FalseRejectSucess\"\n",
    "    FAS = \"FalseAcceptSucess\"\n",
    "    FRE = \"FalseRejectError\"\n",
    "    FAE = \"FalseAcceptError\"\n",
    "    FR1 = \"FalseReject1\"\n",
    "    FR2 = \"FalseReject2\"\n",
    "    \n",
    "    out = {\"class\": [], \"auth\": []}\n",
    "\n",
    "    auth_score: dict[str, dict[str, int]] = {}\n",
    "    class_score: dict[str, dict[str, int]] = {}\n",
    "\n",
    "    # for every user\n",
    "    for attacker_index, attacker_user in enumerate(user_profiles_evaluation):\n",
    "        print(f\"progress: {((attacker_index + 1) / len(user_profiles_evaluation)) * 100:.1f}%\", end='\\r')\n",
    "        # attack with each sample\n",
    "        for attacker_sample_index, attacker_sample in enumerate(attacker_user.get_samples()):\n",
    "            \n",
    "            # calculate distances between attacker sample and each attacked user profiles\n",
    "            mean_distances: dict[str, list[float]] = get_mean_distances(user_profiles_training, attacker_sample, attacker_sample_index, attacker_index)\n",
    "\n",
    "            # every attacked user\n",
    "            for attacked_index, attacked_user in enumerate(user_profiles_training):\n",
    "                # try classification and authentification for each distance measure\n",
    "                for distance_measure in mean_distances.keys():\n",
    "                    # init counter\n",
    "                    if class_score.get(distance_measure) is None: class_score[distance_measure] = {FRA:0,FAA:0,FRS:0,FAS:0,FRE:0,FAE:0, FR1:0, FR2:0}\n",
    "                    if auth_score.get(distance_measure) is None: auth_score[distance_measure] = {FRA:0,FAA:0,FRS:0,FAS:0,FRE:0,FAE:0, FR1:0, FR2:0}\n",
    "\n",
    "                    # try to classifiy user\n",
    "                    # user with smallest distance from profile to sample\n",
    "                    classified_user_index = user_classification(mean_distances, distance_measure)\n",
    "\n",
    "                    # check if attacker and attacked are the same\n",
    "                    same_user = attacker_index == attacked_index\n",
    "\n",
    "                    # check if the attacked user was classified\n",
    "                    attacked_user_classifified = classified_user_index == attacked_index\n",
    "\n",
    "                    # valid classification/authentification -> False Reject Attempt\n",
    "                    if same_user:\n",
    "                        class_score[distance_measure][FRA] += 1\n",
    "                        auth_score[distance_measure][FRA] += 1\n",
    "                    # imposter classification/authentification -> False Accept Attempt\n",
    "                    else:\n",
    "                        class_score[distance_measure][FAA] += 1\n",
    "                        auth_score[distance_measure][FAA] += 1\n",
    "    \n",
    "                    # user attacks itself and classification suceeded, \n",
    "                    # False Reject\n",
    "                    if same_user and attacked_user_classifified:\n",
    "                        # False Reject Success\n",
    "                        class_score[distance_measure][FRS] += 1\n",
    "\n",
    "                        # check second auth step\n",
    "                        if authentification_legitimate(mean_distances, distance_measure, attacked_user, attacked_index,attacker_sample_index):\n",
    "                        #if authentification(mean_distances, distance_measure, attacked_user, attacked_index):\n",
    "                            # False Reject Sucess\n",
    "                            auth_score[distance_measure][FRS] += 1\n",
    "                        else:\n",
    "                            # False Reject Error\n",
    "                            auth_score[distance_measure][FRE] += 1\n",
    "                            auth_score[distance_measure][FR1] += 1\n",
    "\n",
    "                    # user attacks itself and classification failed\n",
    "                    # False Reject Error\n",
    "                    elif same_user and not attacked_user_classifified:\n",
    "                        # False Reject Error\n",
    "                        class_score[distance_measure][FRE] += 1\n",
    "                        auth_score[distance_measure][FRE] += 1\n",
    "                        auth_score[distance_measure][FR2] += 1\n",
    "                \n",
    "                    # user attacks other user and classification suceeded\n",
    "                    # False Accept\n",
    "                    elif not same_user and attacked_user_classifified:\n",
    "                        # False Accept Error\n",
    "                        class_score[distance_measure][FAE] += 1\n",
    "\n",
    "                        # check second auth step\n",
    "                        if authentification(mean_distances, distance_measure, attacked_user, attacked_index):\n",
    "                            # False Accept Error\n",
    "                            auth_score[distance_measure][FAE] += 1\n",
    "                        else:\n",
    "                            # False Accept Sucess\n",
    "                            auth_score[distance_measure][FAS] += 1\n",
    "\n",
    "                    # user attacks other user and classification failed\n",
    "                    # False Accept Success\n",
    "                    elif not same_user and not attacked_user_classifified:\n",
    "                        class_score[distance_measure][FAS] += 1\n",
    "                        auth_score[distance_measure][FAS] += 1\n",
    "\n",
    "                    else: assert False\n",
    "\n",
    "    # check results\n",
    "    for distance_measure in class_score.keys():\n",
    "        c_value: dict[str, int] = class_score[distance_measure]\n",
    "        a_value: dict[str, int] = auth_score[distance_measure]\n",
    "\n",
    "        # attempts = sucess + errors\n",
    "        assert c_value[FRA] == (c_value[FRS] + c_value[FRE])\n",
    "        assert c_value[FAA] == (c_value[FAS] + c_value[FAE])\n",
    "\n",
    "        # attempts = sucess + errors\n",
    "        assert a_value[FRA] == (a_value[FRS] + a_value[FRE])\n",
    "        assert a_value[FAA] == (a_value[FAS] + a_value[FAE])\n",
    "\n",
    "        # classification False Accept Error \n",
    "        # have to be equal or greater then authentifiation False Accept Errors\n",
    "        # because the second auth check can correct a wrong classification\n",
    "        assert c_value[FAE] >= a_value[FAE]\n",
    "\n",
    "        # auth False Reject Error \n",
    "        # have to be equal or greater then classification False Reject Errors\n",
    "        # because the second auth check can fail a successfull classification\n",
    "        assert a_value[FRE] >= c_value[FRE]\n",
    "\n",
    "    # produce output\n",
    "    for (distance_measure, value) in class_score.items():\n",
    "        out[\"class\"].append({\n",
    "            \"dist\": distance_measure, \n",
    "            \"FalseAcceptAttempts\" : value[FAA],\n",
    "            \"FalseRejectAttempts\": value[FRA],\n",
    "            #\"FalseAcceptSucess\": value[FAS],\n",
    "            #\"FalseRejectSucess\": value[FRS],\n",
    "            \"FalseAcceptError\": value[FAE],\n",
    "            \"FalseRejectError\": value[FRE], \n",
    "            })\n",
    "\n",
    "    for (distance_measure, value) in auth_score.items():\n",
    "        out[\"auth\"].append({\n",
    "            \"dist\": distance_measure, \n",
    "            \"FalseAcceptAttempts\" : value[FAA],\n",
    "            \"FalseRejectAttempts\": value[FRA],\n",
    "            #\"FalseAcceptSucess\": value[FAS],\n",
    "            #\"FalseRejectSucess\": value[FRS],\n",
    "            \"FalseAcceptError\": value[FAE],\n",
    "            \"FalseRejectError\": value[FRE], \n",
    "            \"FalseReject1\": value[FR1],\n",
    "            \"FalseReject2\": value[FR2]\n",
    "        })\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment setup and output\n",
    "def experiment(path_to_dataset_training: str,path_to_dataset_evaluation: str, output: str, filter: list = []): \n",
    "    # open training data set\n",
    "    with open(path_to_dataset_training, \"rb\") as fp:\n",
    "        user_profiles_training = pickle.load(fp)\n",
    "\n",
    "    # open eval data sets\n",
    "    with open(path_to_dataset_evaluation, \"rb\") as fp:\n",
    "        user_profiles_evaluation = pickle.load(fp)\n",
    "\n",
    "    # remove filtered rows: [13, 18, 26]\n",
    "    user_profiles_training = [UserProfile(j) for i, j in enumerate(user_profiles_training) if i not in filter]\n",
    "    user_profiles_evaluation = [UserProfile(j) for i, j in enumerate(user_profiles_evaluation) if i not in filter]\n",
    "\n",
    "    results: dict[str, list[dict]] = execute(user_profiles_training, user_profiles_evaluation)\n",
    "    \n",
    "    class_results: list[dict] = results[\"class\"]\n",
    "    auth_results: list[dict] = results[\"auth\"]\n",
    "\n",
    "    class_results_df: pd.DataFrame = pd.DataFrame(class_results)\n",
    "    auth_results_df: pd.DataFrame = pd.DataFrame(auth_results)\n",
    "\n",
    "    class_results_df.to_csv(f\"./{data_folder}/\" + output + \"_classification_data.csv\", index=False)\n",
    "    auth_results_df.to_csv(f\"./{data_folder}/\" + output + \"_authentification_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original data\n",
    "original_set = \"./FreeText-Dataset-31-USERS.csv\"\n",
    "original_data_profiles = f\"./{data_folder}/original_data_profiles\"\n",
    "\n",
    "if not os.path.isfile(original_data_profiles):\n",
    "    create_user_profiles(original_set, original_data_profiles)\n",
    "\n",
    "experiment(original_data_profiles, original_data_profiles, \"original\", filter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chrome isolated\n",
    "chrome_isolated_set = \"./chrome/isolated/complete.csv\"\n",
    "chrome_isolated_data_profiles = f\"./{data_folder}/chrome_isolated_data_profiles\"\n",
    "\n",
    "if not os.path.isfile(chrome_isolated_data_profiles):\n",
    "    create_user_profiles(chrome_isolated_set, chrome_isolated_data_profiles)\n",
    "\n",
    "experiment(chrome_isolated_data_profiles,chrome_isolated_data_profiles,\"chrome_isolated\",filter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chrome unisolated\n",
    "chrome_unisolated_set = \"./chrome/unisolated/complete.csv\"\n",
    "chrome_unisolated_data_profiles = f\"./{data_folder}/chrome_unisolated_data_profiles\"\n",
    "\n",
    "if not os.path.isfile(chrome_unisolated_data_profiles):\n",
    "    create_user_profiles(chrome_unisolated_set, chrome_unisolated_data_profiles)\n",
    "\n",
    "experiment(chrome_unisolated_data_profiles,chrome_unisolated_data_profiles,\"chrome_unisolated\",filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chromium isolated\n",
    "chromium_isolated_set = \"./chromium/isolated/complete.csv\"\n",
    "chromium_isolated_data_profiles = f\"./{data_folder}/chromium_isolated_data_profiles\"\n",
    "\n",
    "if not os.path.isfile(chromium_isolated_data_profiles):\n",
    "    create_user_profiles(chromium_isolated_set, chromium_isolated_data_profiles)\n",
    "\n",
    "experiment(chromium_isolated_data_profiles, chromium_isolated_data_profiles, \"chromium_isolated\", filter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chromium unisolated\n",
    "chromium_unisolated_set = \"./chromium/unisolated/complete.csv\"\n",
    "chromium_unisolated_data_profiles = f\"./{data_folder}/chromium_unisolated_data_profiles\"\n",
    "\n",
    "if not os.path.isfile(chromium_unisolated_data_profiles):\n",
    "    create_user_profiles(chromium_unisolated_set, chromium_unisolated_data_profiles)\n",
    "\n",
    "experiment(chromium_unisolated_data_profiles, chromium_unisolated_data_profiles, \"chromium_unisolated\", filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge isolated\n",
    "edge_isolated_set = \"./edge/isolated/complete.csv\"\n",
    "edge_isolated_data_profiles = f\"./{data_folder}/edge_isolated_data_profiles\"\n",
    "\n",
    "if not os.path.isfile(edge_isolated_data_profiles):\n",
    "    create_user_profiles(edge_isolated_set, edge_isolated_data_profiles)\n",
    "\n",
    "experiment(edge_isolated_data_profiles, edge_isolated_data_profiles, \"edge_isolated\", filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edge unisolated\n",
    "edge_unisolated_set = \"./edge/unisolated/complete.csv\"\n",
    "edge_unisolated_data_profiles = f\"./{data_folder}/edge_unisolated_data_profiles\"\n",
    "\n",
    "if not os.path.isfile(edge_unisolated_data_profiles):\n",
    "    create_user_profiles(edge_unisolated_set, edge_unisolated_data_profiles)\n",
    "\n",
    "experiment(edge_unisolated_data_profiles, edge_unisolated_data_profiles, \"edge_unisolated\", filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tor unisolated\n",
    "tor_unisolated_set = \"./tor/unisolated/complete.csv\"\n",
    "tor_unisolated_data_profiles = f\"./{data_folder}/tor_unisolated_data_profiles\"\n",
    "\n",
    "if not os.path.isfile(tor_unisolated_data_profiles):\n",
    "    create_user_profiles(tor_unisolated_set, tor_unisolated_data_profiles)\n",
    "\n",
    "experiment(tor_unisolated_data_profiles, tor_unisolated_data_profiles, \"tor_unisolated\", filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# safari isolated\n",
    "safari_isolated_set = \"./safari/isolated/complete.csv\"\n",
    "safari_isolated_data_profiles = f\"./{data_folder}/safari_isolated_data_profiles\"\n",
    "\n",
    "if not os.path.isfile(safari_isolated_data_profiles):\n",
    "    create_user_profiles(safari_isolated_set, safari_isolated_data_profiles)\n",
    "\n",
    "experiment(safari_isolated_data_profiles, safari_isolated_data_profiles, \"safari_isolated\", filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# safari unisolated\n",
    "safari_unisolated_set = \"./safari/unisolated/complete.csv\"\n",
    "safari_unisolated_data_profiles = f\"./{data_folder}/safari_unisolated_data_profiles\"\n",
    "\n",
    "if not os.path.isfile(safari_unisolated_data_profiles):\n",
    "    create_user_profiles(safari_unisolated_set, safari_unisolated_data_profiles)\n",
    "\n",
    "experiment(safari_unisolated_data_profiles, safari_unisolated_data_profiles, \"safari_unisolated\", filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# firefox isolated\n",
    "firefox_isolated_set = \"./firefox/isolated/complete.csv\"\n",
    "firefox_isolated_data_profiles = f\"./{data_folder}/firefox_isolated_data_profiles\"\n",
    "\n",
    "if not os.path.isfile(firefox_isolated_data_profiles):\n",
    "    create_user_profiles(firefox_isolated_set, firefox_isolated_data_profiles)\n",
    "\n",
    "experiment(firefox_isolated_data_profiles, firefox_isolated_data_profiles, \"firefox_isolated\", filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# firefox unisolated\n",
    "firefox_unisolated_set = \"./firefox/unisolated/complete.csv\"\n",
    "firefox_unisolated_data_profiles = f\"./{data_folder}/firefox_unisolated_data_profiles\"\n",
    "\n",
    "if not os.path.isfile(firefox_unisolated_data_profiles):\n",
    "    create_user_profiles(firefox_unisolated_set, firefox_unisolated_data_profiles)\n",
    "\n",
    "experiment(firefox_unisolated_data_profiles, firefox_unisolated_data_profiles, \"firefox_unisolated\", filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# firefox isolated resistFP\n",
    "firefox_resistFP_isolated_set = \"./firefox_rf/isolated/complete.csv\"\n",
    "firefox_resistFP_isolated_data_profiles = (\n",
    "    f\"./{data_folder}/firefox_resistFP_isolated_data_profiles\"\n",
    ")\n",
    "\n",
    "if not os.path.isfile(firefox_resistFP_isolated_data_profiles):\n",
    "    create_user_profiles(\n",
    "        firefox_resistFP_isolated_set, firefox_resistFP_isolated_data_profiles\n",
    "    )\n",
    "\n",
    "experiment(firefox_resistFP_isolated_data_profiles, firefox_resistFP_isolated_data_profiles, \"firefox_resistFP_isolated\", filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# firefox unisolated resistFP\n",
    "firefox_resistFP_unisolated_set = \"./firefox_rf/unisolated/complete.csv\"\n",
    "firefox_resistFP_unisolated_data_profiles = (\n",
    "    f\"./{data_folder}/firefox_resistFP_unisolated_data_profiles\"\n",
    ")\n",
    "\n",
    "if not os.path.isfile(firefox_resistFP_unisolated_data_profiles):\n",
    "    create_user_profiles(firefox_resistFP_unisolated_set, firefox_resistFP_unisolated_data_profiles)\n",
    "\n",
    "experiment(firefox_resistFP_unisolated_data_profiles,firefox_resistFP_unisolated_data_profiles,\"firefox_resistFP_unisolated\",filter,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# firefox unisolated resistFP 20ms\n",
    "firefox_resistFP_20ms_unisolated_set = \"./firefox_rf_20/unisolated/complete.csv\"\n",
    "firefox_resistFP_20ms_unisolated_data_profiles = (\n",
    "    f\"./{data_folder}/firefox_resistFP_20ms_unisolated_data_profiles\"\n",
    ")\n",
    "\n",
    "if not os.path.isfile(firefox_resistFP_20ms_unisolated_data_profiles):\n",
    "    create_user_profiles(firefox_resistFP_20ms_unisolated_set, firefox_resistFP_20ms_unisolated_data_profiles)\n",
    "\n",
    "experiment(firefox_resistFP_20ms_unisolated_data_profiles, firefox_resistFP_20ms_unisolated_data_profiles, \"firefox_resistFP_20ms_unisolated\", filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# firefox unisolated resistFP 33ms\n",
    "firefox_resistFP_33ms_unisolated_set = \"./firefox_rf_33/unisolated/complete.csv\"\n",
    "firefox_resistFP_33ms_unisolated_data_profiles = (\n",
    "    f\"./{data_folder}/firefox_resistFP_33ms_unisolated_data_profiles\"\n",
    ")\n",
    "\n",
    "if not os.path.isfile(firefox_resistFP_33ms_unisolated_data_profiles):\n",
    "    create_user_profiles(firefox_resistFP_33ms_unisolated_set,firefox_resistFP_33ms_unisolated_data_profiles)\n",
    "\n",
    "experiment(firefox_resistFP_33ms_unisolated_data_profiles, firefox_resistFP_33ms_unisolated_data_profiles,\"firefox_resistFP_33ms_unisolated\",filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# firefox unisolated resistFP 40ms\n",
    "firefox_resistFP_40ms_unisolated_set = \"./firefox_rf_40/unisolated/complete.csv\"\n",
    "firefox_resistFP_40ms_unisolated_data_profiles = (\n",
    "    f\"./{data_folder}/firefox_resistFP_40ms_unisolated_data_profiles\"\n",
    ")\n",
    "\n",
    "if not os.path.isfile(firefox_resistFP_40ms_unisolated_data_profiles):\n",
    "    create_user_profiles(firefox_resistFP_40ms_unisolated_set, firefox_resistFP_40ms_unisolated_data_profiles)\n",
    "\n",
    "experiment(firefox_resistFP_40ms_unisolated_data_profiles, firefox_resistFP_40ms_unisolated_data_profiles, \"firefox_resistFP_40ms_unisolated\", filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# firefox unisolated resistFP 60ms\n",
    "firefox_resistFP_60ms_unisolated_set = \"./firefox_rf_60/unisolated/complete.csv\"\n",
    "firefox_resistFP_60ms_unisolated_data_profiles = (\n",
    "    f\"./{data_folder}/firefox_resistFP_60ms_unisolated_data_profiles\"\n",
    ")\n",
    "\n",
    "if not os.path.isfile(firefox_resistFP_60ms_unisolated_data_profiles):\n",
    "    create_user_profiles(firefox_resistFP_60ms_unisolated_set, firefox_resistFP_60ms_unisolated_data_profiles)\n",
    "\n",
    "experiment(firefox_resistFP_60ms_unisolated_data_profiles, firefox_resistFP_60ms_unisolated_data_profiles,\"firefox_resistFP_60ms_unisolated\",filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# firefox unisolated resistFP 80ms\n",
    "firefox_resistFP_80ms_unisolated_set = \"./firefox_rf_80/unisolated/complete.csv\"\n",
    "firefox_resistFP_80ms_unisolated_data_profiles = (\n",
    "    f\"./{data_folder}/firefox_resistFP_80ms_unisolated_data_profiles\"\n",
    ")\n",
    "\n",
    "if not os.path.isfile(firefox_resistFP_80ms_unisolated_data_profiles):\n",
    "    create_user_profiles(firefox_resistFP_80ms_unisolated_set,firefox_resistFP_80ms_unisolated_data_profiles)\n",
    "\n",
    "experiment(firefox_resistFP_80ms_unisolated_data_profiles, firefox_resistFP_80ms_unisolated_data_profiles,\"firefox_resistFP_80ms_unisolated\",filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# firefox unisolated resistFP 100ms\n",
    "firefox_resistFP_100ms_unisolated_set = \"./firefox_rf_100/unisolated/complete.csv\"\n",
    "firefox_resistFP_100ms_unisolated_data_profiles = (\n",
    "    f\"./{data_folder}/firefox_resistFP_100ms_unisolated_data_profiles\"\n",
    ")\n",
    "\n",
    "if not os.path.isfile(firefox_resistFP_100ms_unisolated_data_profiles):\n",
    "    create_user_profiles(firefox_resistFP_100ms_unisolated_set,firefox_resistFP_100ms_unisolated_data_profiles,)\n",
    "\n",
    "experiment(firefox_resistFP_100ms_unisolated_data_profiles,firefox_resistFP_100ms_unisolated_data_profiles,\"firefox_resistFP_100ms_unisolated\",filter,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# firefox unisolated resistFP 120ms\n",
    "firefox_resistFP_120ms_unisolated_set = \"./firefox_rf_120/unisolated/complete.csv\"\n",
    "firefox_resistFP_120ms_unisolated_data_profiles = (\n",
    "    f\"./{data_folder}/firefox_resistFP_120ms_unisolated_data_profiles\"\n",
    ")\n",
    "\n",
    "if not os.path.isfile(firefox_resistFP_120ms_unisolated_data_profiles):\n",
    "    create_user_profiles(firefox_resistFP_120ms_unisolated_set,firefox_resistFP_120ms_unisolated_data_profiles,)\n",
    "\n",
    "experiment(firefox_resistFP_120ms_unisolated_data_profiles,firefox_resistFP_120ms_unisolated_data_profiles,\"firefox_resistFP_120ms_unisolated\",filter,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# firefox unisolated resistFP 140ms\n",
    "firefox_resistFP_140ms_unisolated_set = \"./firefox_rf_140/unisolated/complete.csv\"\n",
    "firefox_resistFP_140ms_unisolated_data_profiles = (\n",
    "    f\"./{data_folder}/firefox_resistFP_140ms_unisolated_data_profiles\"\n",
    ")\n",
    "\n",
    "if not os.path.isfile(firefox_resistFP_140ms_unisolated_data_profiles):\n",
    "    create_user_profiles(firefox_resistFP_140ms_unisolated_set,firefox_resistFP_140ms_unisolated_data_profiles,)\n",
    "\n",
    "experiment(firefox_resistFP_140ms_unisolated_data_profiles,firefox_resistFP_140ms_unisolated_data_profiles,\"firefox_resistFP_140ms_unisolated\",filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# firefox unisolated resistFP 160ms\n",
    "firefox_resistFP_160ms_unisolated_set = \"./firefox_rf_160/unisolated/complete.csv\"\n",
    "firefox_resistFP_160ms_unisolated_data_profiles = (\n",
    "    f\"./{data_folder}/firefox_resistFP_160ms_unisolated_data_profiles\"\n",
    ")\n",
    "\n",
    "if not os.path.isfile(firefox_resistFP_160ms_unisolated_data_profiles):\n",
    "    create_user_profiles(firefox_resistFP_160ms_unisolated_set,firefox_resistFP_160ms_unisolated_data_profiles,)\n",
    "\n",
    "experiment(firefox_resistFP_160ms_unisolated_data_profiles,firefox_resistFP_160ms_unisolated_data_profiles,\"firefox_resistFP_160ms_unisolated\",filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# firefox unisolated resistFP 180ms\n",
    "firefox_resistFP_180ms_unisolated_set = \"./firefox_rf_180/unisolated/complete.csv\"\n",
    "firefox_resistFP_180ms_unisolated_data_profiles = (\n",
    "    f\"./{data_folder}/firefox_resistFP_180ms_unisolated_data_profiles\"\n",
    ")\n",
    "\n",
    "if not os.path.isfile(firefox_resistFP_180ms_unisolated_data_profiles):\n",
    "    create_user_profiles(firefox_resistFP_180ms_unisolated_set,firefox_resistFP_180ms_unisolated_data_profiles,)\n",
    "\n",
    "experiment(firefox_resistFP_180ms_unisolated_data_profiles,firefox_resistFP_180ms_unisolated_data_profiles,\"firefox_resistFP_180ms_unisolated\",filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# firefox unisolated resistFP 200ms\n",
    "firefox_resistFP_200ms_unisolated_set = \"./firefox_rf_200/unisolated/complete.csv\"\n",
    "firefox_resistFP_200ms_unisolated_data_profiles = (\n",
    "    f\"./{data_folder}/firefox_resistFP_200ms_unisolated_data_profiles\"\n",
    ")\n",
    "\n",
    "if not os.path.isfile(firefox_resistFP_200ms_unisolated_data_profiles):\n",
    "    create_user_profiles(firefox_resistFP_200ms_unisolated_set,firefox_resistFP_200ms_unisolated_data_profiles,)\n",
    "\n",
    "experiment(firefox_resistFP_200ms_unisolated_data_profiles,firefox_resistFP_200ms_unisolated_data_profiles,\"firefox_resistFP_200ms_unisolated\",filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# firefox unisolated resistFP NJ\n",
    "firefox_resistFP_NJ_unisolated_set = \"./firefox_rf_NJ/unisolated/complete.csv\"\n",
    "firefox_resistFP_NJ_unisolated_data_profiles = (\n",
    "    f\"./{data_folder}/firefox_resistFP_NJ_unisolated_data_profiles\"\n",
    ")\n",
    "\n",
    "if not os.path.isfile(firefox_resistFP_NJ_unisolated_data_profiles):\n",
    "    create_user_profiles(firefox_resistFP_NJ_unisolated_set, firefox_resistFP_NJ_unisolated_data_profiles)\n",
    "\n",
    "experiment(firefox_resistFP_NJ_unisolated_data_profiles,firefox_resistFP_NJ_unisolated_data_profiles,\"firefox_resistFP_NJ_unisolated\",filter,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# firefox unisolated resistFP 20ms NJ\n",
    "firefox_resistFP_20ms_NJ_unisolated_set = \"./firefox_rf_20_NJ/unisolated/complete.csv\"\n",
    "firefox_resistFP_20ms_NJ_unisolated_data_profiles = (\n",
    "    f\"./{data_folder}/firefox_resistFP_20ms_NJ_unisolated_data_profiles\"\n",
    ")\n",
    "\n",
    "if not os.path.isfile(firefox_resistFP_20ms_NJ_unisolated_data_profiles):\n",
    "    create_user_profiles(firefox_resistFP_20ms_NJ_unisolated_set,firefox_resistFP_20ms_NJ_unisolated_data_profiles,)\n",
    "\n",
    "experiment(firefox_resistFP_20ms_NJ_unisolated_data_profiles,firefox_resistFP_20ms_NJ_unisolated_data_profiles,\"firefox_resistFP_20ms_NJ_unisolated\",filter,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# firefox unisolated resistFP 33ms NJ\n",
    "firefox_resistFP_33ms_NJ_unisolated_set = \"./firefox_rf_33_NJ/unisolated/complete.csv\"\n",
    "firefox_resistFP_33ms_NJ_unisolated_data_profiles = (\n",
    "    f\"./{data_folder}/firefox_resistFP_33ms_NJ_unisolated_data_profiles\"\n",
    ")\n",
    "\n",
    "if not os.path.isfile(firefox_resistFP_33ms_NJ_unisolated_data_profiles):\n",
    "    create_user_profiles(firefox_resistFP_33ms_NJ_unisolated_set,firefox_resistFP_33ms_NJ_unisolated_data_profiles,)\n",
    "\n",
    "experiment(firefox_resistFP_33ms_NJ_unisolated_data_profiles,firefox_resistFP_33ms_NJ_unisolated_data_profiles,\"firefox_resistFP_33ms_NJ_unisolated\",filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# firefox unisolated resistFP 40ms NJ\n",
    "firefox_resistFP_40ms_NJ_unisolated_set = \"./firefox_rf_40_NJ/unisolated/complete.csv\"\n",
    "firefox_resistFP_40ms_NJ_unisolated_data_profiles = (\n",
    "    f\"./{data_folder}/firefox_resistFP_40ms_NJ_unisolated_data_profiles\"\n",
    ")\n",
    "\n",
    "if not os.path.isfile(firefox_resistFP_40ms_NJ_unisolated_data_profiles):\n",
    "    create_user_profiles(firefox_resistFP_40ms_NJ_unisolated_set,firefox_resistFP_40ms_NJ_unisolated_data_profiles,)\n",
    "\n",
    "experiment(firefox_resistFP_40ms_NJ_unisolated_data_profiles,firefox_resistFP_40ms_NJ_unisolated_data_profiles,\"firefox_resistFP_40ms_NJ_unisolated\",filter,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# firefox unisolated resistFP 60ms NJ\n",
    "firefox_resistFP_60ms_NJ_unisolated_set = \"./firefox_rf_60_NJ/unisolated/complete.csv\"\n",
    "firefox_resistFP_60ms_NJ_unisolated_data_profiles = (\n",
    "    f\"./{data_folder}/firefox_resistFP_60ms_NJ_unisolated_data_profiles\"\n",
    ")\n",
    "\n",
    "if not os.path.isfile(firefox_resistFP_60ms_NJ_unisolated_data_profiles):\n",
    "    create_user_profiles(firefox_resistFP_60ms_NJ_unisolated_set,firefox_resistFP_60ms_NJ_unisolated_data_profiles)\n",
    "\n",
    "experiment(firefox_resistFP_60ms_NJ_unisolated_data_profiles,firefox_resistFP_60ms_NJ_unisolated_data_profiles,\"firefox_resistFP_60ms_NJ_unisolated\",filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# firefox unisolated resistFP 80ms NJ\n",
    "firefox_resistFP_80ms_NJ_unisolated_set = \"./firefox_rf_80_NJ/unisolated/complete.csv\"\n",
    "firefox_resistFP_80ms_NJ_unisolated_data_profiles = (\n",
    "    f\"./{data_folder}/firefox_resistFP_80ms_NJ_unisolated_data_profiles\"\n",
    ")\n",
    "\n",
    "if not os.path.isfile(firefox_resistFP_80ms_NJ_unisolated_data_profiles):\n",
    "    create_user_profiles(firefox_resistFP_80ms_NJ_unisolated_set, firefox_resistFP_80ms_NJ_unisolated_data_profiles)\n",
    "\n",
    "experiment(firefox_resistFP_80ms_NJ_unisolated_data_profiles, firefox_resistFP_80ms_NJ_unisolated_data_profiles, \"firefox_resistFP_80ms_NJ_unisolated\", filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# firefox unisolated resistFP 100ms NJ\n",
    "firefox_resistFP_100ms_NJ_unisolated_set = \"./firefox_rf_100_NJ/unisolated/complete.csv\"\n",
    "firefox_resistFP_100ms_NJ_unisolated_data_profiles = (\n",
    "    f\"./{data_folder}/firefox_resistFP_100ms_NJ_unisolated_data_profiles\"\n",
    ")\n",
    "\n",
    "if not os.path.isfile(firefox_resistFP_100ms_NJ_unisolated_data_profiles):\n",
    "    create_user_profiles(firefox_resistFP_100ms_NJ_unisolated_set, firefox_resistFP_100ms_NJ_unisolated_data_profiles)\n",
    "\n",
    "experiment(firefox_resistFP_100ms_NJ_unisolated_data_profiles, firefox_resistFP_100ms_NJ_unisolated_data_profiles, \"firefox_resistFP_100ms_NJ_unisolated\",filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# firefox unisolated resistFP 120ms NJ\n",
    "firefox_resistFP_120ms_NJ_unisolated_set = \"./firefox_rf_120_NJ/unisolated/complete.csv\"\n",
    "firefox_resistFP_120ms_NJ_unisolated_data_profiles = (\n",
    "    f\"./{data_folder}/firefox_resistFP_120ms_NJ_unisolated_data_profiles\"\n",
    ")\n",
    "\n",
    "if not os.path.isfile(firefox_resistFP_120ms_NJ_unisolated_data_profiles):\n",
    "    create_user_profiles(firefox_resistFP_120ms_NJ_unisolated_set,firefox_resistFP_120ms_NJ_unisolated_data_profiles)\n",
    "\n",
    "experiment(firefox_resistFP_120ms_NJ_unisolated_data_profiles, firefox_resistFP_120ms_NJ_unisolated_data_profiles, \"firefox_resistFP_120ms_NJ_unisolated\", filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# firefox unisolated resistFP 140ms NJ\n",
    "firefox_resistFP_140ms_NJ_unisolated_set = \"./firefox_rf_140_NJ/unisolated/complete.csv\"\n",
    "firefox_resistFP_140ms_NJ_unisolated_data_profiles = (\n",
    "    f\"./{data_folder}/firefox_resistFP_140ms_NJ_unisolated_data_profiles\"\n",
    ")\n",
    "\n",
    "if not os.path.isfile(firefox_resistFP_140ms_NJ_unisolated_data_profiles):\n",
    "    create_user_profiles(firefox_resistFP_140ms_NJ_unisolated_set, firefox_resistFP_140ms_NJ_unisolated_data_profiles)\n",
    "\n",
    "experiment(firefox_resistFP_140ms_NJ_unisolated_data_profiles, firefox_resistFP_140ms_NJ_unisolated_data_profiles, \"firefox_resistFP_140ms_NJ_unisolated\", filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# firefox unisolated resistFP 160ms NJ\n",
    "firefox_resistFP_160ms_NJ_unisolated_set = \"./firefox_rf_160_NJ/unisolated/complete.csv\"\n",
    "firefox_resistFP_160ms_NJ_unisolated_data_profiles = (\n",
    "    f\"./{data_folder}/firefox_resistFP_160ms_NJ_unisolated_data_profiles\"\n",
    ")\n",
    "\n",
    "if not os.path.isfile(firefox_resistFP_160ms_NJ_unisolated_data_profiles):\n",
    "    create_user_profiles(firefox_resistFP_160ms_NJ_unisolated_set, firefox_resistFP_160ms_NJ_unisolated_data_profiles)\n",
    "\n",
    "experiment(firefox_resistFP_160ms_NJ_unisolated_data_profiles,firefox_resistFP_160ms_NJ_unisolated_data_profiles, \"firefox_resistFP_160ms_NJ_unisolated\", filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# firefox unisolated resistFP 180ms NJ\n",
    "firefox_resistFP_180ms_NJ_unisolated_set = \"./firefox_rf_180_NJ/unisolated/complete.csv\"\n",
    "firefox_resistFP_180ms_NJ_unisolated_data_profiles = (\n",
    "    f\"./{data_folder}/firefox_resistFP_180ms_NJ_unisolated_data_profiles\"\n",
    ")\n",
    "\n",
    "if not os.path.isfile(firefox_resistFP_180ms_NJ_unisolated_data_profiles):\n",
    "    create_user_profiles(firefox_resistFP_180ms_NJ_unisolated_set, firefox_resistFP_180ms_NJ_unisolated_data_profiles)\n",
    "\n",
    "experiment(firefox_resistFP_180ms_NJ_unisolated_data_profiles, firefox_resistFP_180ms_NJ_unisolated_data_profiles, \"firefox_resistFP_180ms_NJ_unisolated\", filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# firefox unisolated resistFP 200ms NJ\n",
    "firefox_resistFP_200ms_NJ_unisolated_set = \"./firefox_rf_200_NJ/unisolated/complete.csv\"\n",
    "firefox_resistFP_200ms_NJ_unisolated_data_profiles = (\n",
    "    f\"./{data_folder}/firefox_resistFP_200ms_NJ_unisolated_data_profiles\"\n",
    ")\n",
    "\n",
    "if not os.path.isfile(firefox_resistFP_200ms_NJ_unisolated_data_profiles):\n",
    "    create_user_profiles(firefox_resistFP_200ms_NJ_unisolated_set, firefox_resistFP_200ms_NJ_unisolated_data_profiles)\n",
    "\n",
    "experiment(firefox_resistFP_200ms_NJ_unisolated_data_profiles, firefox_resistFP_200ms_NJ_unisolated_data_profiles, \"firefox_resistFP_200ms_NJ_unisolated\", filter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
